{"version":3,"sources":["PublicComponent/Header.js","PublicComponent/Footer.js","PublicComponent/FailImage.js","Main/AboutMe.js","Main/MainAlertArea.js","Main/MainPage.js","Posts/PostsMain.js","Notes/NotesMain.js","PublicComponent/PageHeader.js","Posts/MyPosts/HowDoNeuralNetworkWork.js","Posts/MyPosts/WhatIsLSTM.js","Router.js","App.js","reportWebVitals.js","index.js"],"names":["Header","Layout","AppHeader","props","style","position","zIndex","width","padding","className","theme","mode","defaultSelectedKeys","select","Item","to","Footer","AppFooter","textAlign","failImage","Link","Typography","Title","Paragraph","AboutMe","backgroundColor","level","size","align","height","src","process","fallback","copyable","MailOutlined","href","ZhihuOutlined","MainAlertArea","state","AlertList","message","description","type","showIcon","this","setState","length","SetEmptyArea","direction","React","Component","Content","Text","MainContent","window","scrollTo","marginTop","margin","strong","ApiOutlined","orientation","MainPost","closable","title","extra","PlusOutlined","color","ellipsis","rows","expandable","MainNotes","gutter","span","bordered","hoverable","FilePdfOutlined","fontSize","BookOutlined","AppPageHeader","onBack","history","back","subTitle","PhotoLink","HowDoNeuralNetworkWork","PostContent","math","FailImage","language","lightfair","children","WhatIsLSTM","alt","BasicRoute","exact","path","component","App","reportWebVitals","onPerfEntry","Function","then","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"4QAQQA,EAAWC,IAAXD,OAqBOE,MAnBf,SAAmBC,GACf,OACI,eAACH,EAAD,CAAQI,MAAO,CAAEC,SAAU,QAASC,OAAQ,EAAGC,MAAO,OAAQC,QAAQ,KAAtE,UACE,qBAAKC,UAAU,SACf,eAAC,IAAD,CAAMC,MAAM,QAAQC,KAAK,aAAaC,oBAAqB,CAACT,EAAMU,QAAlE,UACE,cAAC,IAAKC,KAAN,UACE,cAAC,IAAD,CAAMC,GAAG,IAAT,mBADa,KAGf,cAAC,IAAKD,KAAN,UACE,cAAC,IAAD,CAAMC,GAAG,SAAT,oBADa,KAGf,cAAC,IAAKD,KAAN,UACE,cAAC,IAAD,CAAMC,GAAG,SAAT,oBADa,YCdpBC,EAAUf,IAAVe,OASQC,MAPf,WACI,OAAQ,eAACD,EAAD,CAAQZ,MAAO,CAAEc,UAAW,UAA5B,wBACe,uBADf,qD,oCCRGC,EAFG,iqGCSVC,EAA2BC,IAA3BD,KAAME,EAAqBD,IAArBC,MAAOC,EAAcF,IAAdE,UAiCNC,MA9Bf,WACI,OACI,eAAC,IAAD,CAAQpB,MAAO,CAAEqB,gBAAiB,QAASjB,QAAS,KAApD,UACI,cAACc,EAAD,CAAOI,MAAO,EAAd,sBAEA,eAAC,IAAD,CACIC,KAAK,QACLC,MAAM,QAFV,UAKA,cAAC,IAAD,CACIrB,MAAO,IACPsB,OAAQ,IACRC,IAAG,UAfDC,YAeC,eACHC,SAAUb,IAGd,eAACI,EAAD,WACA,cAACD,EAAD,CAAOI,MAAO,EAAd,yBACI,eAACH,EAAD,CAAWU,UAAQ,EAAnB,UAAoB,cAACC,EAAA,EAAD,IAApB,+BAFJ,UAGW,cAACd,EAAD,CAAMe,KAAK,wCAAX,mDACP,uBACA,cAACC,EAAA,EAAD,IALJ,gBAKiC,cAAChB,EAAD,CAAMe,KAAK,kDAAX,uE,iDCoB9BE,E,4MAvCXC,MAAQ,CACJC,UAAY,CACR,cAAC,IAAD,CACAC,QAAQ,UACRC,YAAY,yCACZC,KAAK,UACLC,UAAQ,IAGR,cAAC,IAAD,CACAH,QAAQ,cACRC,YAAY,sFACZC,KAAK,OACLC,UAAQ,M,6DAKZC,KAAKC,SACD,CACIN,UAAY,cAAC,IAAD,CAAOE,YAAY,gB,+BAQvC,OAHoC,IAAhCG,KAAKN,MAAMC,UAAUO,QACrBF,KAAKG,eAGL,cAAC,IAAD,CACIC,UAAU,WACV5C,MAAO,CAACG,MAAO,QAFnB,SAIKqC,KAAKN,MAAMC,gB,GAlCAU,IAAMC,WCD3BC,EAAWlD,IAAXkD,QACA7B,EAA0BD,IAA1BC,MAAOC,EAAmBF,IAAnBE,UAAW6B,EAAQ/B,IAAR+B,KA4CVC,EAzCK,WAEhB,OADAC,OAAOC,SAAS,EAAE,GAEd,eAAC,IAAD,WACA,cAAC,EAAD,CAAW1C,OAAO,MAClB,eAACsC,EAAD,CAAS1C,UAAU,cAAcL,MAAO,CAAEI,QAAS,SAAUgD,UAAW,IAAxE,UAEE,eAAC,IAAD,CAAYpD,MAAO,CAAEqD,OAAQ,UAA7B,UACE,cAAC,IAAW3C,KAAZ,mBACA,cAAC,IAAWA,KAAZ,2BAGF,sBAAKL,UAAU,yBAAyBL,MAAO,CAAEI,QAAS,IAA1D,UACE,cAAC,EAAD,IAEA,cAAC,IAAD,IAEA,cAAC,EAAD,CAAOkB,MAAO,EAAd,4BALF,+GAQE,uBAEA,cAAC0B,EAAD,CAAMM,QAAM,EAAZ,6CACA,cAAC,EAAD,CAAWzB,UAAQ,EAAnB,6DAEA,eAAC,IAAD,CAAQS,KAAK,UAAUP,KAAK,kDAA5B,UACI,cAACwB,EAAA,EAAD,IADJ,wBAIA,cAAC,IAAD,CAASC,YAAY,OAArB,kCAGA,cAAC,EAAD,UAIJ,cAAC,EAAD,Q,2BCzCDT,EAAWlD,IAAXkD,QACA7B,EAAoBD,IAApBC,MAAOC,EAAaF,IAAbE,UAyECsC,EAvEE,WAEb,OADAP,OAAOC,SAAS,EAAE,GAEd,eAAC,IAAD,WACA,cAAC,EAAD,CAAW1C,OAAO,MAClB,eAAC,EAAD,CAASJ,UAAU,cAAcL,MAAO,CAAEI,QAAS,SAAUgD,UAAW,IAAxE,UAEE,eAAC,IAAD,CAAYpD,MAAO,CAAEqD,OAAQ,UAA7B,UACE,cAAC,IAAW3C,KAAZ,mBACA,cAAC,IAAWA,KAAZ,uBAGF,sBAAKL,UAAU,yBAAyBL,MAAO,CAAEI,QAAS,IAA1D,UACA,cAAC,EAAD,CAAOkB,MAAO,EAAd,mBAEE,eAAC,IAAD,CAAOsB,UAAU,WAAWrB,KAAK,SAASvB,MAAO,CAAEG,MAAO,QAA1D,UAEA,cAAC,IAAD,CACIiC,QAAQ,UACRC,YAAY,yCACZC,KAAK,UACLC,UAAQ,EACRmB,UAAQ,IAGZ,cAAC,IAAD,CACItB,QAAQ,UACRC,YAAY,8IACZC,KAAK,UACLC,UAAQ,EACRmB,UAAQ,IAGZ,cAAC,IAAD,CACItB,QAAQ,cACRC,YAAY,sFACZC,KAAK,OACLC,UAAQ,EACRmB,UAAQ,IAGZ,cAAC,IAAD,CAASF,YAAY,OAArB,SAA4B,cAAC,EAAD,CAAOlC,MAAO,EAAd,8BAE5B,eAAC,IAAD,CAAMgB,KAAK,QAAQqB,MAAM,6BAA6BC,MAAO,eAAC,IAAD,CAAMjD,GAAG,gCAAT,kBAA8C,cAACkD,EAAA,EAAD,OAA3G,UACI,cAAC,IAAD,CAAKC,MAAM,OAAX,4BADJ,IAC2C,cAAC,IAAD,CAAKA,MAAM,OAAX,qCAA+C,cAAC,IAAD,CAAKA,MAAM,OAAX,8BACtF,cAAC,IAAD,IACA,cAAC,EAAD,CACAC,SAAU,CACNC,KAAM,EACNC,YAAY,GAHhB,22BAOJ,eAAC,IAAD,CAAM3B,KAAK,QAAQqB,MAAM,eAAeC,MAAO,eAAC,IAAD,CAAMjD,GAAG,oBAAT,kBAAkC,cAACkD,EAAA,EAAD,OAAjF,UACI,cAAC,IAAD,CAAKC,MAAM,OAAX,4BADJ,IAC2C,cAAC,IAAD,CAAKA,MAAM,OAAX,qCAA+C,cAAC,IAAD,CAAKA,MAAM,OAAX,8BACtF,cAAC,IAAD,IACA,cAAC,EAAD,CACAC,SAAU,CACNC,KAAM,EACNC,YAAY,GAHhB,y7CAUR,cAAC,EAAD,Q,kCCtEDlB,EAAWlD,IAAXkD,QACA7B,GAAeD,IAAfC,MAAO8B,GAAQ/B,IAAR+B,KA+JCkB,GA5JG,WAEd,OADAhB,OAAOC,SAAS,EAAE,GAEd,eAAC,IAAD,WACA,cAAC,EAAD,CAAW1C,OAAO,MAClB,eAAC,EAAD,CAASJ,UAAU,cAAcL,MAAO,CAAEI,QAAS,SAAUgD,UAAW,IAAxE,UAEE,eAAC,IAAD,CAAYpD,MAAO,CAAEqD,OAAQ,UAA7B,UACE,cAAC,IAAW3C,KAAZ,mBACA,cAAC,IAAWA,KAAZ,uBAGF,sBAAKL,UAAU,yBAAyBL,MAAO,CAAEI,QAAS,IAA1D,UAEA,cAAC,GAAD,CAAOkB,MAAO,EAAd,gCAEE,qBAAKjB,UAAU,oBAAf,SACA,eAAC,IAAD,CACIuC,UAAU,WACV5C,MAAO,CAACG,MAAO,QAFnB,UAIA,eAAC,IAAD,CAAKgE,OAAQ,GAAb,UACA,cAAC,IAAD,CAAKC,KAAM,EAAX,SACA,mBAAGrC,KAAK,8DAAR,SACI,cAAC,IAAD,CAAM4B,MAAM,WAAWU,UAAU,EAAOC,WAAW,EAAnD,SACA,eAAC,IAAD,CAAO1B,UAAU,WAAjB,UACA,cAAC2B,EAAA,EAAD,CAAiBvE,MAAO,CAAEwE,SAAU,UACpC,cAAC,GAAD,CAAMlC,KAAK,YAAX,wBACA,cAAC,IAAD,CAAKwB,MAAM,QAAX,6BAKJ,cAAC,IAAD,CAAKM,KAAM,EAAX,SACA,mBAAGrC,KAAK,8DAAR,SACI,cAAC,IAAD,CAAM4B,MAAM,aAAaU,UAAU,EAAOC,WAAW,EAArD,SACA,eAAC,IAAD,CAAO1B,UAAU,WAAjB,UACA,cAAC2B,EAAA,EAAD,CAAiBvE,MAAO,CAAEwE,SAAU,UACpC,cAAC,GAAD,CAAMlC,KAAK,YAAX,wBACA,cAAC,IAAD,CAAKwB,MAAM,QAAX,6BAKJ,cAAC,IAAD,CAAKM,KAAM,EAAX,SACA,4BACI,cAAC,IAAD,CAAMT,MAAM,OAAOU,UAAU,EAAOC,WAAW,EAA/C,SACA,eAAC,IAAD,CAAO1B,UAAU,WAAjB,UACA,cAAC2B,EAAA,EAAD,CAAiBvE,MAAO,CAAEwE,SAAU,UACpC,cAAC,IAAD,CAAKV,MAAM,MAAX,iCAMJ,eAAC,IAAD,CAAKK,OAAQ,GAAb,UACA,cAAC,IAAD,CAAKC,KAAM,EAAX,SACA,mBAAGrC,KAAK,8DAAR,SACI,cAAC,IAAD,CAAM4B,MAAM,UAAUU,UAAU,EAAOC,WAAW,EAAlD,SACA,eAAC,IAAD,CAAO1B,UAAU,WAAjB,UACA,cAAC2B,EAAA,EAAD,CAAiBvE,MAAO,CAAEwE,SAAU,UACpC,cAAC,GAAD,CAAMlC,KAAK,YAAX,wBACA,cAAC,IAAD,CAAKwB,MAAM,QAAX,6BAKJ,cAAC,IAAD,CAAKM,KAAM,EAAX,SACA,mBAAGrC,KAAK,8DAAR,SACI,cAAC,IAAD,CAAM4B,MAAM,YAAYU,UAAU,EAAOC,WAAW,EAApD,SACA,eAAC,IAAD,CAAO1B,UAAU,WAAjB,UACA,cAAC2B,EAAA,EAAD,CAAiBvE,MAAO,CAAEwE,SAAU,UACpC,cAAC,GAAD,CAAMlC,KAAK,YAAX,wBACA,cAAC,IAAD,CAAKwB,MAAM,QAAX,6BAKJ,cAAC,IAAD,CAAKM,KAAM,EAAX,SACA,mBAAGrC,KAAK,8DAAR,SACI,cAAC,IAAD,CAAM4B,MAAM,cAAcU,UAAU,EAAOC,WAAW,EAAtD,SACA,eAAC,IAAD,CAAO1B,UAAU,WAAjB,UACA,cAAC2B,EAAA,EAAD,CAAiBvE,MAAO,CAAEwE,SAAU,UACpC,cAAC,GAAD,CAAMlC,KAAK,YAAX,uBACA,cAAC,IAAD,CAAKwB,MAAM,QAAX,gCAMJ,eAAC,IAAD,CAAKK,OAAQ,GAAb,UACA,cAAC,IAAD,CAAKC,KAAM,EAAX,SACA,4BACI,cAAC,IAAD,CAAMT,MAAM,YAAYU,UAAU,EAAOC,WAAW,EAApD,SACA,eAAC,IAAD,CAAO1B,UAAU,WAAjB,UACA,cAAC2B,EAAA,EAAD,CAAiBvE,MAAO,CAAEwE,SAAU,UACpC,cAAC,IAAD,CAAKV,MAAM,MAAX,8BAKJ,cAAC,IAAD,CAAKM,KAAM,EAAX,SACA,4BACI,cAAC,IAAD,CAAMT,MAAM,iBAAiBU,UAAU,EAAOC,WAAW,EAAzD,SACA,eAAC,IAAD,CAAO1B,UAAU,WAAjB,UACA,cAAC2B,EAAA,EAAD,CAAiBvE,MAAO,CAAEwE,SAAU,UACpC,cAAC,IAAD,CAAKV,MAAM,MAAX,8BAKJ,cAAC,IAAD,CAAKM,KAAM,EAAX,SACA,4BACI,cAAC,IAAD,CAAMT,MAAM,iBAAiBU,UAAU,EAAOC,WAAW,EAAzD,SACA,eAAC,IAAD,CAAO1B,UAAU,WAAjB,UACA,cAAC2B,EAAA,EAAD,CAAiBvE,MAAO,CAAEwE,SAAU,UACpC,cAAC,IAAD,CAAKV,MAAM,MAAX,iCAMJ,eAAC,IAAD,CAAKK,OAAQ,GAAb,UACA,cAAC,IAAD,CAAKC,KAAM,EAAX,SACA,mBAAGrC,KAAK,4IAAR,SACI,cAAC,IAAD,CAAM4B,MAAM,WAAWU,UAAU,EAAOC,WAAW,EAAnD,SACA,eAAC,IAAD,CAAO1B,UAAU,WAAjB,UACA,cAAC6B,EAAA,EAAD,CAAczE,MAAO,CAAEwE,SAAU,UACjC,cAAC,GAAD,CAAMlC,KAAK,YAAX,4BACA,cAAC,IAAD,CAAKwB,MAAM,QAAX,6BAKJ,cAAC,IAAD,CAAKM,KAAM,EAAX,SACA,mBAAGrC,KAAK,6IAAR,SACI,cAAC,IAAD,CAAM4B,MAAM,WAAWU,UAAU,EAAOC,WAAW,EAAnD,SACA,eAAC,IAAD,CAAO1B,UAAU,WAAjB,UACA,cAAC6B,EAAA,EAAD,CAAczE,MAAO,CAAEwE,SAAU,UACjC,cAAC,GAAD,CAAMlC,KAAK,YAAX,4BACA,cAAC,IAAD,CAAKwB,MAAM,QAAX,2CAWR,cAAC,EAAD,Q,+CCpJOY,OAXf,SAAuB3E,GACnB,OACI,cAAC,KAAD,CACIM,UAAU,mBACVsE,OAAQ,kBAAMzB,OAAO0B,QAAQC,QAC7BlB,MAAO5D,EAAM4D,MACbmB,SAAU/E,EAAM+E,YCKpB5D,GAA2BD,IAA3BC,MAAO8B,GAAoB/B,IAApB+B,KAAM7B,GAAcF,IAAdE,UACb4B,GAAYlD,IAAZkD,QACFgC,GAAYpD,YAkBHqD,OAhBf,SAAgCjF,GAE5B,OADAmD,OAAOC,SAAS,EAAE,GAEtB,eAAC,IAAD,WACQ,cAAC,EAAD,CAAW1C,OAAO,MAClB,eAAC,GAAD,CAASJ,UAAU,cAAcL,MAAO,CAAEI,QAAS,SAAUgD,UAAW,IAAxE,UACA,cAAC,GAAD,CAAeO,MAAM,+BACnB,qBAAKtD,UAAU,yBAAyBL,MAAO,CAAEI,QAAS,IAA1D,SACI,cAAC6E,GAAD,SAGN,cAAC,EAAD,QAOR,SAASA,KACL,OACI,eAAC,IAAD,CAAQjF,MAAO,CAAEqB,gBAAiB,QAASjB,QAAS,KAApD,UACA,gCACA,cAAC,IAAD,CAAK0D,MAAM,OAAX,4BADA,IACuC,cAAC,IAAD,CAAKA,MAAM,OAAX,qCAA+C,cAAC,IAAD,CAAKA,MAAM,OAAX,iCAEtF,cAAC,IAAD,IACA,cAAC,GAAD,y2BAEA,eAAC,GAAD,+MAA4C,cAAC,GAAD,CAAMR,QAAM,EAAZ,kDAA5C,8BAEA,cAAC,GAAD,CAAOhC,MAAO,EAAd,2DACA,cAAC,GAAD,+JACA,cAAC,aAAD,CAAW4D,KAAK,mDAChB,eAAC,GAAD,4ZAA+E,cAAC,cAAD,CAAYA,KAAK,SAAhG,OACA,eAAC,GAAD,sFAAuB,cAAC,cAAD,CAAYA,KAAK,6CACxC,eAAC,GAAD,CAAW5C,KAAK,YAAhB,oEAAqD,cAAC,cAAD,CAAY4C,KAAK,kEAAtE,2CACA,eAAC,GAAD,oHAA4B,cAAC,GAAD,CAAM5B,QAAM,EAAZ,kJAA5B,uFAAoF,cAAC,cAAD,CAAY4B,KAAK,SAArG,8EAAsI,cAAC,cAAD,CAAYA,KAAK,SAAvJ,qHAAkL,cAAC,cAAD,CAAYA,KAAK,SAAnM,iIAAgO,cAAC,cAAD,CAAYA,KAAK,SAAjP,4EAAsQ,cAAC,cAAD,CAAYA,KAAK,SAAvR,gDAEA,cAAC,GAAD,CAAO5D,MAAO,EAAd,2DACA,cAAC,GAAD,2QACA,eAAC,GAAD,kMAAyC,cAAC,cAAD,CAAY4D,KAAK,YAA1D,qGAAsF,cAAC,cAAD,CAAYA,KAAK,yBAAvG,2EAA0I,cAAC,cAAD,CAAYA,KAAK,2FAA3J,sGACA,iCAAQ,cAAC,IAAD,CACJ/E,MAAM,QACNuB,IAAG,UAAKqD,GAAL,+BACHnD,SAAUuD,MAEd,cAAC,aAAD,CAAWD,KAAK,yHAEhB,cAAC,GAAD,CAAO5D,MAAO,EAAd,6EACA,eAAC,GAAD,wSAA0D,cAAC,GAAD,CAAMgC,QAAM,EAAZ,4FAA1D,qEAAsG,cAAC,GAAD,CAAMhB,KAAK,UAAX,wDAAtG,sGACA,cAAC,GAAD,uPACA,iCAAQ,eAAC,IAAD,WACR,cAAC,IAAD,CACInC,MAAM,QACNuB,IAAG,UAAKqD,GAAL,+BACHnD,SAAUuD,IAEd,cAAC,IAAD,CACIhF,MAAM,QACNuB,IAAG,UAAKqD,GAAL,+BACHnD,SAAUuD,SAGd,cAAC,KAAD,CAAmBC,SAAS,SAASpF,MAAOqF,KAC5CC,SAAQ,mtBAmCR,eAAC,GAAD,kGAAyB,cAAC,cAAD,CAAYJ,KAAK,4BAA1C,+YAAsI,cAAC,cAAD,CAAYA,KAAK,4BAAvJ,wBACA,iCAAQ,cAAC,IAAD,CACJ/E,MAAM,QACNuB,IAAG,UAAKqD,GAAL,+BACHnD,SAAUuD,MAEd,cAAC,KAAD,CACAnF,MAAOqF,KACPD,SAAS,SACTE,SAAQ,wgBAsBR,cAAC,GAAD,CAAOhE,MAAO,EAAd,6EACA,eAAC,GAAD,q5BAA8K,cAAC,cAAD,CAAY4D,KAAK,SAA/L,iCAA4M,cAAC,cAAD,CAAYA,KAAK,SAA7N,kBACA,eAAC,GAAD,+RAA2D,cAAC,cAAD,CAAYA,KAAK,SAA5E,SAAqF,cAAC,cAAD,CAAYA,KAAK,SAAtG,kKAA2I,cAAC,cAAD,CAAYA,KAAK,YAA5J,sIAAgM,cAAC,cAAD,CAAYA,KAAK,YAAjN,6CAAkO,cAAC,cAAD,CAAYA,KAAK,SAAnP,2BAA+P,cAAC,cAAD,CAAYA,KAAK,SAAhR,uCAA8R,cAAC,cAAD,CAAYA,KAAK,YAA/S,qCACA,cAAC,GAAD,CAAO5D,MAAO,EAAd,sCACA,eAAC,GAAD,iOAA+C,cAAC,cAAD,CAAY4D,KAAK,SAAhE,qBAA2E,cAAC,cAAD,CAAYA,KAAK,SAA5F,6CAA2G,cAAC,cAAD,CAAYA,KAAK,mBAA5H,qBAAgJ,cAAC,cAAD,CAAYA,KAAK,aAAjK,sEAAkM,cAAC,cAAD,CAAYA,KAAK,MAAnN,8KAEA,cAAC,GAAD,uSAGA,eAAC,GAAD,0EAAqB,cAAC,cAAD,CAAYA,KAAK,yCAEtC,cAAC,GAAD,CAAO5D,MAAO,EAAd,oEACA,eAAC,GAAD,4JAAsC,cAAC,cAAD,CAAY4D,KAAK,YAAvD,scAA8I,cAAC,cAAD,CAAYA,KAAK,YAA/J,6GAEA,eAAC,GAAD,8JAAmC,cAAC,cAAD,CAAYA,KAAK,SAApD,2JAAuF,cAAC,cAAD,CAAYA,KAAK,UAAxG,6FAAgI,cAAC,cAAD,CAAYA,KAAK,MAAjJ,2BAA0J,cAAC,cAAD,CAAYA,KAAK,SAA3K,2EAA+L,cAAC,cAAD,CAAYA,KAAK,SAAhN,wHACA,cAAC,aAAD,CAAWA,KAAK,4IAChB,eAAC,GAAD,gCAAc,cAAC,cAAD,CAAYA,KAAK,UAA/B,6IAA8D,cAAC,cAAD,CAAYA,KAAK,MAA/E,qBAAuF,cAAC,cAAD,CAAYA,KAAK,MAAxG,6DACA,eAAC,GAAD,gIAA8B,cAAC,cAAD,CAAYA,KAAK,YAA/C,4KAAsF,cAAC,cAAD,CAAYA,KAAK,+CAAvG,sBAAqJ,cAAC,cAAD,CAAYA,KAAK,YAAtK,4DACA,cAAC,aAAD,CAAWA,KAAK,yLAChB,eAAC,GAAD,CAAW5C,KAAK,YAAhB,0EAAuC,cAAC,cAAD,CAAY4C,KAAK,mBAAxD,0DAAmF,cAAC,cAAD,CAAYA,KAAK,YAApG,wCAAqH,cAAC,cAAD,CAAYA,KAAK,wDAAtI,mBAEA,eAAC,GAAD,CAAW5C,KAAK,YAAhB,mHAA6C,cAAC,cAAD,CAAY4C,KAAK,aAA9D,+GAA2F,cAAC,cAAD,CAAYA,KAAK,kBAA5G,yDAAqI,cAAC,GAAD,CAAM5B,QAAM,EAAZ,sCAArI,eAA+J,cAAC,cAAD,CAAY4B,KAAK,uDAChL,cAAC,aAAD,CAAWA,KAAK,mKADhB,2JAIA,cAAC,GAAD,ghB,IC/JAhE,GAAiCD,IAAjCC,MAAO8B,GAA0B/B,IAA1B+B,KAAM7B,GAAoBF,IAApBE,UAAWH,GAASC,IAATD,KACxB+B,GAAYlD,IAAZkD,QACFgC,GAAYpD,YAkBH4D,OAhBf,WAEI,OADArC,OAAOC,SAAS,EAAE,GAEd,eAAC,IAAD,WACA,cAAC,EAAD,CAAW1C,OAAO,MAClB,eAAC,GAAD,CAASJ,UAAU,cAAcL,MAAO,CAAEI,QAAS,SAAUgD,UAAW,IAAxE,UACA,cAAC,GAAD,CAAeO,MAAM,iBACnB,qBAAKtD,UAAU,yBAAyBL,MAAO,CAAEI,QAAS,IAA1D,SACI,cAAC,GAAD,SAGN,cAAC,EAAD,QAOR,SAAS6E,KACL,OACA,eAAC,IAAD,CAAQjF,MAAO,CAAEqB,gBAAiB,QAASjB,QAAS,KAApD,UACI,gCACA,cAAC,IAAD,CAAK0D,MAAM,OAAX,4BADA,IACuC,cAAC,IAAD,CAAKA,MAAM,OAAX,qCADvC,IACuF,cAAC,IAAD,CAAKA,MAAM,OAAX,8BACvF,cAAC,IAAD,OAEA,cAAC,GAAD,86CACA,cAAC,GAAD,CAAOxC,MAAO,EAAd,2EACA,cAAC,GAAD,UAAW,cAAC,GAAD,CAAMgC,QAAM,EAAZ,yCACX,cAAC,GAAD,UAAW,cAAC,GAAD,CAAMA,QAAM,EAAZ,qDACX,cAAC,GAAD,UAAW,cAAC,GAAD,CAAMA,QAAM,EAAZ,qDACX,cAAC,GAAD,UAAW,cAAC,GAAD,CAAMA,QAAM,EAAZ,qDACX,cAAC,GAAD,UAAW,cAAC,GAAD,CAAMA,QAAM,EAAZ,yCACX,cAAC,GAAD,UAAW,cAAC,GAAD,CAAMA,QAAM,EAAZ,2CACX,uBACA,cAAC,GAAD,CAAOhC,MAAO,EAAd,uCACA,eAAC,GAAD,iIAAwD,cAAC,GAAD,CAAMgC,QAAM,EAAZ,kDAAxD,2WAC0D,cAAC,cAAD,CAAY4B,KAAK,MAD3E,mDACwF,cAAC,cAAD,CAAYA,KAAK,UADzG,6CACyH,cAAC,GAAD,CAAM5B,QAAM,EAAZ,sCADzH,4NAE+B,cAAC,GAAD,CAAMA,QAAM,EAAZ,kDAF/B,yGAEwG,cAAC,GAAD,CAAMA,QAAM,EAAZ,sCAFxG,sEAE4I,cAAC,cAAD,CAAY4B,KAAK,MAF7J,4DAGS,cAAC,cAAD,CAAYA,KAAK,QAH1B,kOAGuE,cAAC,GAAD,CAAM5B,QAAM,EAAZ,kDAHvE,qKAIA,iCAAQ,cAAC,IAAD,CAAOkC,IAAI,0BAA0B9D,IAAG,UAAKqD,GAAL,aAA2B5E,MAAM,QAAQyB,SAAUuD,MACnG,eAAC,GAAD,sCAAe,cAAC,cAAD,CAAYD,KAAK,QAAhC,eAAyC,cAAC,cAAD,CAAYA,KAAK,MAA1D,mDAAuE,cAAC,cAAD,CAAYA,KAAK,QAAxF,eAAiG,cAAC,cAAD,CAAYA,KAAK,MAAlH,yGAAwI,cAAC,cAAD,CAAYA,KAAK,MAAzJ,qEAAyK,cAAC,cAAD,CAAYA,KAAK,SAA1L,mDAA0M,cAAC,cAAD,CAAYA,KAAK,MAA3N,wBACA,eAAC,GAAD,kJAAiC,cAAC,GAAD,CAAM5B,QAAM,EAAZ,4CAAjC,yNAEA,eAAC,GAAD,kJAAiC,cAAC,GAAD,CAAMA,QAAM,EAAZ,kDAAjC,mKAEA,cAAC,GAAD,CAAWhB,KAAK,YAAhB,SACA,eAAC,GAAD,mQAAiF,cAAC,GAAD,CAAMgB,QAAM,EAAZ,kBAAjF,eAEA,eAAC,GAAD,oLAA0C,cAAC,cAAD,CAAY4B,KAAK,UAA3D,kEAEA,cAAC,GAAD,CAAW5C,KAAK,YAAhB,SACA,cAAC,GAAD,+QAEA,cAAC,GAAD,myBAGA,eAAC,GAAD,2MAA6C,cAAC,GAAD,CAAMgB,QAAM,EAAZ,kDAA7C,2MAC+B,cAAC,GAAD,CAAMA,QAAM,EAAZ,kDAD/B,2SAEuC,cAAC,cAAD,CAAY4B,KAAK,iBAFxD,SAEyE,cAAC,cAAD,CAAYA,KAAK,iBAF1F,iLAEuI,cAAC,GAAD,CAAM5B,QAAM,EAAZ,qHAFvI,wHAIA,cAAC,GAAD,+tCAIA,cAAC,GAAD,CAAOhC,MAAO,EAAd,mDACA,eAAC,GAAD,gMAA4C,cAAC,GAAD,CAAMgC,QAAM,EAAZ,kDAA5C,yZAEA,cAAC,GAAD,CAAOhC,MAAO,EAAd,oDACA,cAAC,GAAD,8WAEA,cAAC,GAAD,CAAWgB,KAAK,YAAhB,SACA,cAAC,GAAD,wiBAGA,cAAC,GAAD,sfAEA,+BACA,8RACA,qRAEA,cAAC,GAAD,wVAEA,cAAC,GAAD,CAAOhB,MAAO,EAAd,mDACA,cAAC,GAAD,kIACA,iCAAQ,cAAC,IAAD,CAAOkE,IAAI,0BAA0B9D,IAAG,UAAKqD,GAAL,aAA2B5E,MAAM,MAAMyB,SAAUuD,MACjG,eAAC,GAAD,iFAAuB,cAAC,cAAD,CAAYD,KAAK,QAAxC,uCAAqD,cAAC,cAAD,CAAYA,KAAK,QAAtE,iCAAkF,cAAC,cAAD,CAAYA,KAAK,MAAnG,2BAA4G,cAAC,cAAD,CAAYA,KAAK,MAA7H,iCAAuI,cAAC,cAAD,CAAYA,KAAK,QAAxJ,kMACc,cAAC,cAAD,CAAYA,KAAK,QAD/B,8BAEA,cAAC,GAAD,0MACA,iCAAQ,cAAC,IAAD,CAAOM,IAAI,0BAA0B9D,IAAG,UAAKqD,GAAL,aAA2B5E,MAAM,MAAMyB,SAAUuD,MACjG,cAAC,GAAD,0aAEA,eAAC,GAAD,CAAW7C,KAAK,YAAhB,UACA,cAAC,GAAD,kEACA,cAAC,GAAD,qMACA,cAAC,GAAD,uCACA,eAAC,GAAD,6MAAyD,cAAC,cAAD,CAAY4C,KAAK,MAA1E,yCACI,cAAC,cAAD,CAAYA,KAAK,MADrB,gIACmD,cAAC,cAAD,CAAYA,KAAK,SADpE,UAEA,cAAC,aAAD,CAAWA,KAAK,6CAFhB,gHAKmB,cAAC,cAAD,CAAYA,KAAK,SALpC,wFAKqE,cAAC,cAAD,CAAYA,KAAK,YALtF,sBAKoG,cAAC,cAAD,CAAYA,KAAK,kBAErH,cAAC,GAAD,CAAO5D,MAAO,EAAd,kEACA,eAAC,GAAD,mdAC0B,cAAC,cAAD,CAAY4D,KAAK,QAD3C,uCACwD,cAAC,cAAD,CAAYA,KAAK,MADzE,gHAEe,cAAC,cAAD,CAAYA,KAAK,QAFhC,0IAGA,iCAAQ,cAAC,IAAD,CAAOM,IAAI,0BAA0B9D,IAAG,UAAKqD,GAAL,aAA2B5E,MAAM,MAAMyB,SAAUuD,MACjG,cAAC,GAAD,iJACA,cAAC,GAAD,CAAO7D,MAAO,EAAd,uCACA,iCAAQ,cAAC,IAAD,CAAOkE,IAAI,0BAA0B9D,IAAG,UAAKqD,GAAL,aAA2B5E,MAAM,MAAMyB,SAAUuD,MACjG,cAAC,GAAD,0lBAEA,eAAC,GAAD,8mBAC+D,cAAC,cAAD,CAAYD,KAAK,WADhF,w1BAEqH,cAAC,GAAD,CAAM5B,QAAM,EAAZ,+DAFrH,4GAIA,eAAC,GAAD,sIAA+B,cAAC,cAAD,CAAY4B,KAAK,QAAhD,4EACA,cAAC,aAAD,CAAWA,KAAK,2DAGhB,cAAC,GAAD,CAAO5D,MAAO,EAAd,2CACA,eAAC,GAAD,sFAAuB,cAAC,cAAD,CAAY4D,KAAK,MAAxC,ilBAGA,iCAAQ,cAAC,IAAD,CAAOM,IAAI,0BAA0B9D,IAAG,UAAKqD,GAAL,aAA2B5E,MAAM,MAAMyB,SAAUuD,MACjG,+BACA,0GACA,8SAEA,cAAC,GAAD,uJACA,+BACA,6BACA,cAAC,GAAD,UAAW,cAAC,aAAD,CAAWD,KAAK,6DAI3B,6BACA,cAAC,GAAD,UAAW,cAAC,aAAD,CAAWA,KAAK,+DAK3B,cAAC,GAAD,CAAO5D,MAAO,EAAd,uCACA,eAAC,GAAD,6YACc,cAAC,cAAD,CAAY4D,KAAK,oBAD/B,iOAEkB,cAAC,cAAD,CAAYA,KAAK,YAFnC,aAGA,eAAC,GAAD,CAAW5C,KAAK,YAAhB,UACA,cAAC,GAAD,UAAW,cAAC,GAAD,CAAMgB,QAAM,EAAZ,8HACX,cAAC,GAAD,oKACA,cAAC,GAAD,CAAMvB,KAAK,2FAAX,sGACA,cAAC,GAAD,qJACA,+BACA,0DAAQ,cAAC,GAAD,CAAMuB,QAAM,EAAZ,kDAAR,4MAEA,sHAAkB,cAAC,GAAD,CAAMA,QAAM,EAAZ,yCAClB,4FACA,gIAGA,eAAC,GAAD,6QAAkE,cAAC,cAAD,CAAY4B,KAAK,MAAnF,gDACA,uBACA,cAAC,GAAD,CAAO5D,MAAO,EAAd,wCACA,cAAC,GAAD,6QACA,iCAAQ,cAAC,IAAD,CAAOkE,IAAI,0BAA0B9D,IAAG,UAAKqD,GAAL,aAA2B5E,MAAM,MAAMyB,SAAUuD,MACjG,cAAC,GAAD,0lBAEA,eAAC,GAAD,4GAA8B,cAAC,GAAD,CAAM7B,QAAM,EAAZ,iIAA9B,uJAEA,cAAC,GAAD,CAAOhC,MAAO,EAAd,yCACA,eAAC,GAAD,2DAA8C,6EAA9C,2DACA,eAAC,GAAD,sDAAyC,2CAAzC,wFACA,eAAC,GAAD,0IAAwC,2LAAxC,yDACA,eAAC,GAAD,4FAA6B,wJAA7B,2DACA,eAAC,GAAD,0KAA0C,sOAA1C,2DAEA,eAAC,GAAD,mFAAsE,gDAAtE,0GC1LR,IAcemE,GAdI,kBACf,cAAC,IAAD,UACI,eAAC,IAAD,WACI,cAAC,IAAD,CAAOC,OAAK,EAACC,KAAK,IAAIC,UAAW3C,IACjC,cAAC,IAAD,CAAOyC,OAAK,EAACC,KAAK,SAASC,UAAWnC,IACtC,cAAC,IAAD,CAAOiC,OAAK,EAACC,KAAK,SAASC,UAAW1B,KAEtC,cAAC,IAAD,CAAOwB,OAAK,EAACC,KAAK,gCAAgCC,UAAWZ,KAC7D,cAAC,IAAD,CAAOU,OAAK,EAACC,KAAK,oBAAoBC,UAAWL,WCT9CM,OANf,WACE,OACE,cAAC,GAAD,KCOWC,GAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,8BAAqBC,MAAK,YAAkD,IAA/CC,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAON,GACPO,EAAQP,OCDdQ,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,GAAD,MAEFC,SAASC,eAAe,SAM1Bb,M","file":"static/js/main.87bfb7b6.chunk.js","sourcesContent":["import React from 'react';\r\nimport '../App.css';\r\nimport 'moment/locale/zh-cn';\r\nimport 'antd/dist/antd.css';\r\nimport '../index.css';\r\nimport { Layout, Menu } from 'antd';\r\nimport { Link } from 'react-router-dom';\r\n\r\nconst { Header } = Layout;\r\n\r\nfunction AppHeader(props){\r\n    return (\r\n        <Header style={{ position: 'fixed', zIndex: 1, width: '100%', padding:'0'}}>\r\n          <div className=\"logo\" />\r\n          <Menu theme=\"light\" mode=\"horizontal\" defaultSelectedKeys={[props.select]}>\r\n            <Menu.Item key=\"1\">\r\n              <Link to=\"/\">Home</Link>\r\n            </Menu.Item>\r\n            <Menu.Item key=\"2\">\r\n              <Link to=\"/posts\">Posts</Link>\r\n            </Menu.Item>\r\n            <Menu.Item key=\"3\">\r\n              <Link to=\"/notes\">Notes</Link>\r\n            </Menu.Item>\r\n          </Menu>\r\n        </Header>\r\n    );\r\n};\r\n\r\nexport default AppHeader;","import React from 'react';\r\nimport '../App.css';\r\nimport 'moment/locale/zh-cn';\r\nimport 'antd/dist/antd.css';\r\nimport '../index.css';\r\nimport { Layout } from 'antd';\r\n\r\nconst {Footer} = Layout;\r\n\r\nfunction AppFooter(){\r\n    return (<Footer style={{ textAlign: 'center' }}>\r\n                Mark's Blog<br></br>\r\n                Powered by React App and Ant Design Components\r\n            </Footer>);\r\n}\r\n\r\nexport default AppFooter;","const failImage = \"data:image/png;base64,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\";\r\n\r\nexport default failImage;","import React from 'react';\r\nimport '../App.css'\r\nimport 'antd/dist/antd.css';\r\nimport '../index.css';\r\nimport {Layout, Typography, Image, Space} from 'antd';\r\nimport {MailOutlined, ZhihuOutlined} from '@ant-design/icons';\r\n\r\nimport failImage from '../PublicComponent/FailImage';\r\n\r\nconst { Link, Title, Paragraph } = Typography;\r\nconst PhotoLink = process.env.PUBLIC_URL + '/Assets/';\r\n\r\nfunction AboutMe(){\r\n    return(\r\n        <Layout style={{ backgroundColor: \"white\", padding: \"0\"}}>\r\n            <Title level={2}>About Me</Title>\r\n\r\n            <Space\r\n                size=\"large\"\r\n                align=\"start\"\r\n            >\r\n\r\n            <Image\r\n                width={150}\r\n                height={150}\r\n                src={`${PhotoLink}MyPhoto.jpg`}\r\n                fallback={failImage}\r\n            />\r\n\r\n            <Paragraph>\r\n            <Title level={4}>Yutian Chen</Title>\r\n                <Paragraph copyable><MailOutlined/> markchenyutian@gmail.com</Paragraph>\r\n                ORCiD: <Link href=\"https://orcid.org/0000-0001-8008-9014\">https://orcid.org/0000-0001-8008-9014</Link>\r\n                <br></br>\r\n                <ZhihuOutlined/>  Home Page: <Link href=\"https://www.zhihu.com/people/chen-yu-tian-48-79\">https://www.zhihu.com/people/chen-yu-tian-48-79</Link>\r\n            </Paragraph>\r\n\r\n            </Space>\r\n        </Layout>\r\n    );\r\n}\r\n\r\nexport default AboutMe;","import React from 'react';\r\nimport '../App.css';\r\nimport 'moment/locale/zh-cn';\r\nimport 'antd/dist/antd.css';\r\nimport '../index.css';\r\nimport {Alert, Space, Empty} from 'antd';\r\n\r\n/*\r\nThis Class `MainAlertArea` control the Alert objects on React DOM on AppMainContent.\r\nNew Alerts should be added in MainAlertArea.state.AlertList\r\n\r\nWhere there's no Alert in MainAlertArea.state.AlertList, the Empty State will be applied and rendered automatically\r\n*/\r\n\r\nclass MainAlertArea extends React.Component{\r\n    state = {\r\n        AlertList : [\r\n            <Alert\r\n            message=\"Warning\"\r\n            description=\"This Site is under Active Construction\"\r\n            type=\"warning\"\r\n            showIcon\r\n            />,\r\n\r\n            <Alert\r\n            message=\"Information\"\r\n            description=\"You can access my blog at this url: https://markchenyutian.github.io/Markchen_Blog/\"\r\n            type=\"info\"\r\n            showIcon\r\n            />\r\n        ]\r\n    };\r\n    SetEmptyArea(){\r\n        this.setState(\r\n            {\r\n                AlertList : <Empty description=\"No Info\"/>\r\n            }\r\n        );\r\n    }\r\n    render(){\r\n        if (this.state.AlertList.length === 0){\r\n            this.SetEmptyArea();\r\n        }\r\n        return (\r\n            <Space\r\n                direction=\"vertical\"\r\n                style={{width: \"100%\"}}\r\n            >\r\n                {this.state.AlertList}\r\n            </Space>\r\n        );\r\n}\r\n}\r\n\r\nexport default MainAlertArea;","import React from 'react';\r\nimport '../App.css';\r\nimport 'moment/locale/zh-cn';\r\nimport 'antd/dist/antd.css';\r\nimport '../index.css';\r\nimport { Layout, Breadcrumb, Typography, Divider, Button } from 'antd';\r\nimport {ApiOutlined} from '@ant-design/icons';\r\n\r\nimport AppHeader from '../PublicComponent/Header';\r\nimport AppFooter from '../PublicComponent/Footer';\r\nimport AboutMe from './AboutMe';\r\nimport MainAlertArea from './MainAlertArea';\r\n\r\nconst {Content} = Layout;\r\nconst {Title, Paragraph, Text} = Typography;\r\n\r\n\r\nconst MainContent = () => {\r\n    window.scrollTo(0,0);\r\n    return (\r\n        <Layout>\r\n        <AppHeader select=\"1\"/>\r\n        <Content className=\"site-layout\" style={{ padding: '0 24px', marginTop: 64 }}>\r\n\r\n          <Breadcrumb style={{ margin: '16px 0' }}>\r\n            <Breadcrumb.Item>Home</Breadcrumb.Item>\r\n            <Breadcrumb.Item>Main Page</Breadcrumb.Item>\r\n          </Breadcrumb>\r\n\r\n          <div className=\"site-layout-background\" style={{ padding: 16 }}>\r\n            <AboutMe/>\r\n\r\n            <Divider></Divider>\r\n\r\n            <Title level={2}>About This App</Title>\r\n\r\n            This is the React App of Mark. Currently, the App is under construction, you can access Mark's Blog instead.\r\n            <br></br>\r\n\r\n            <Text strong>Copy the URL to access My Blog:</Text>\r\n            <Paragraph copyable>https://markchenyutian.github.io/Markchen_Blog/</Paragraph>\r\n\r\n            <Button type=\"default\" href=\"https://markchenyutian.github.io/Markchen_Blog/\">\r\n                <ApiOutlined/> Go to Mark's Blog \r\n            </Button>\r\n\r\n            <Divider orientation='left'>\r\n                Notice & Information\r\n            </Divider>\r\n            <MainAlertArea/>\r\n\r\n          </div>\r\n        </Content>\r\n        <AppFooter/>\r\n      </Layout>\r\n    );\r\n};\r\n\r\nexport default MainContent;","import React from 'react';\r\nimport '../App.css';\r\nimport 'moment/locale/zh-cn';\r\nimport 'antd/dist/antd.css';\r\nimport '../index.css';\r\nimport { Layout, Breadcrumb, Typography, Space, Alert, Tag, Card, Divider } from 'antd';\r\nimport {PlusOutlined} from '@ant-design/icons';\r\nimport { Link } from 'react-router-dom';\r\n\r\nimport AppHeader from '../PublicComponent/Header';\r\nimport AppFooter from '../PublicComponent/Footer';\r\n\r\nconst {Content} = Layout;\r\nconst {Title, Paragraph} = Typography;\r\n\r\nconst MainPost = () => {\r\n    window.scrollTo(0,0);\r\n    return (\r\n        <Layout>\r\n        <AppHeader select=\"2\"/>\r\n        <Content className=\"site-layout\" style={{ padding: '0 24px', marginTop: 64 }}>\r\n\r\n          <Breadcrumb style={{ margin: '16px 0' }}>\r\n            <Breadcrumb.Item>Home</Breadcrumb.Item>\r\n            <Breadcrumb.Item>Posts</Breadcrumb.Item>\r\n          </Breadcrumb>\r\n\r\n          <div className=\"site-layout-background\" style={{ padding: 16 }}>\r\n          <Title level={2}>Posts</Title>\r\n\r\n            <Space direction=\"vertical\" size=\"middle\" style={{ width: \"100%\" }}>\r\n\r\n            <Alert\r\n                message=\"Warning\"\r\n                description=\"This Site is under Active Construction\"\r\n                type=\"warning\"\r\n                showIcon\r\n                closable\r\n            />\r\n\r\n            <Alert\r\n                message=\"Warning\"\r\n                description=\"For Better Experience, it is recommended to use PC to access this React App since using window of small width may lead to content overflow.\"\r\n                type=\"warning\"\r\n                showIcon\r\n                closable\r\n            />\r\n\r\n            <Alert\r\n                message=\"Information\"\r\n                description=\"You can access my blog at this url: https://markchenyutian.github.io/Markchen_Blog/\"\r\n                type=\"info\"\r\n                showIcon\r\n                closable\r\n            />\r\n\r\n            <Divider orientation=\"left\"><Title level={4}>Neural Network</Title></Divider>\r\n\r\n            <Card type=\"inner\" title=\"How Do Neural Network Work\" extra={<Link to=\"/posts/HowDoNeuralNetworkWork\">More <PlusOutlined /></Link>}>\r\n                <Tag color=\"blue\">Neural Network</Tag> <Tag color=\"blue\">Artificial Intelligence</Tag><Tag color=\"blue\">Machine Learning</Tag>\r\n                <Divider></Divider>\r\n                <Paragraph\r\n                ellipsis={{\r\n                    rows: 3,\r\n                    expandable: false,\r\n                }}>神经网络作为一种新兴的计算机技术被许多人称为一种全新的“编程范式”，与往常的算法编写不同，神经网络是一种“数据驱动”的编程方法。在往常的算法编写中，人们需要手动编写算法的逻辑，而在神经网络中，人们只需要为网络提供海量数据和参考答案，网络就会自动生成算法。那么神经网络到底是怎么工作的呢？</Paragraph>\r\n            </Card>\r\n\r\n            <Card type=\"inner\" title=\"What Is LSTM\" extra={<Link to=\"/posts/WhatIsLSTM\">More <PlusOutlined /></Link>}>\r\n                <Tag color=\"blue\">Neural Network</Tag> <Tag color=\"blue\">Artificial Intelligence</Tag><Tag color=\"blue\">Machine Learning</Tag>\r\n                <Divider></Divider>\r\n                <Paragraph\r\n                ellipsis={{\r\n                    rows: 3,\r\n                    expandable: false,\r\n                }}>一般的神经网络只能处理单个信息，可是有的时候神经网络的输入是一个时间序列，在这种情况下普通的前馈神经网络就不能利用“上下文”中隐含的信息来更好的处理当前输入。为了解决这个问题，人们提出了递归神经网络(Recurrent Neural Network, RNN)。可是递归神经网络也有问题：由于同样的权重在网络中一直被累乘，在反向传播的时候极容易出现梯度消失与梯度爆炸的问题。同时，由于RNN在状态间传递的信息过少，RNN在上下文距离较远的时候会很快的遗忘前文信息。为了解决这些问题，人们提出了LSTM这个新的网络模型，它可以很好的处理以上这些问题。</Paragraph>\r\n            </Card>\r\n            </Space>\r\n          </div>\r\n\r\n        </Content>\r\n        <AppFooter/>\r\n      </Layout>\r\n    );\r\n};\r\n\r\nexport default MainPost;","import React from 'react';\r\nimport '../App.css';\r\nimport 'moment/locale/zh-cn';\r\nimport 'antd/dist/antd.css';\r\nimport '../index.css';\r\nimport { Layout, Breadcrumb, Typography, Row, Col, Tag, Card, Space } from 'antd';\r\nimport {FilePdfOutlined, BookOutlined} from '@ant-design/icons';\r\n\r\nimport AppHeader from '../PublicComponent/Header';\r\nimport AppFooter from '../PublicComponent/Footer';\r\n\r\nconst {Content} = Layout;\r\nconst {Title, Text} = Typography;\r\n\r\n\r\nconst MainNotes = () => {\r\n    window.scrollTo(0,0);\r\n    return (\r\n        <Layout>\r\n        <AppHeader select=\"3\"/>\r\n        <Content className=\"site-layout\" style={{ padding: '0 24px', marginTop: 64 }}>\r\n\r\n          <Breadcrumb style={{ margin: '16px 0' }}>\r\n            <Breadcrumb.Item>Home</Breadcrumb.Item>\r\n            <Breadcrumb.Item>Notes</Breadcrumb.Item>\r\n          </Breadcrumb>\r\n\r\n          <div className=\"site-layout-background\" style={{ padding: 16 }}>\r\n\r\n          <Title level={3}>Advanced Placement</Title>\r\n\r\n            <div className=\"site-card-wrapper\">\r\n            <Space\r\n                direction=\"vertical\"\r\n                style={{width: \"100%\"}}\r\n            >\r\n            <Row gutter={16}>\r\n            <Col span={8}>\r\n            <a href=\"https://1drv.ms/b/s!AtCdnSj9ls2qhN13evPwPUMWqidPDQ?e=lnHw6E\">\r\n                <Card title=\"Calculus\" bordered={false} hoverable={true}>\r\n                <Space direction=\"vertical\">\r\n                <FilePdfOutlined style={{ fontSize: '30px'}}/>\r\n                <Text type='secondary'> Size: 50M</Text>\r\n                <Tag color=\"green\">Online</Tag>\r\n                </Space>\r\n                </Card>\r\n            </a>\r\n            </Col>\r\n            <Col span={8}>\r\n            <a href=\"https://1drv.ms/b/s!AtCdnSj9ls2qhN4EldJWgEmT3GQ84Q?e=A1BUpZ\">\r\n                <Card title=\"Statistics\" bordered={false} hoverable={true}>\r\n                <Space direction=\"vertical\">\r\n                <FilePdfOutlined style={{ fontSize: '30px'}}/>\r\n                <Text type='secondary'> Size: 50M</Text>\r\n                <Tag color=\"green\">Online</Tag>\r\n                </Space>\r\n                </Card>\r\n            </a>\r\n            </Col>\r\n            <Col span={8}>\r\n            <a>\r\n                <Card title=\"CS A\" bordered={false} hoverable={true}>\r\n                <Space direction=\"vertical\">\r\n                <FilePdfOutlined style={{ fontSize: '30px'}}/>\r\n                <Tag color=\"red\">Offline</Tag>\r\n                </Space>\r\n                </Card>\r\n            </a>\r\n            </Col>\r\n            </Row>\r\n            <Row gutter={16}>\r\n            <Col span={8}>\r\n            <a href=\"https://1drv.ms/b/s!AtCdnSj9ls2qhN12v8FiI_hO4_I3Jg?e=oFDoCn\">\r\n                <Card title=\"Biology\" bordered={false} hoverable={true}>\r\n                <Space direction=\"vertical\">\r\n                <FilePdfOutlined style={{ fontSize: '30px'}}/>\r\n                <Text type='secondary'> Size: 70M</Text>\r\n                <Tag color=\"green\">Online</Tag>\r\n                </Space>\r\n                </Card>\r\n            </a>\r\n            </Col>\r\n            <Col span={8}>\r\n            <a href=\"https://1drv.ms/b/s!AtCdnSj9ls2qhN4FQfxa8Im_2lGjqg?e=gkU8zY\">\r\n                <Card title=\"Physics 2\" bordered={false} hoverable={true}>\r\n                <Space direction=\"vertical\">\r\n                <FilePdfOutlined style={{ fontSize: '30px'}}/>\r\n                <Text type='secondary'> Size: 35M</Text>\r\n                <Tag color=\"green\">Online</Tag>\r\n                </Space>\r\n                </Card>\r\n            </a>\r\n            </Col>\r\n            <Col span={8}>\r\n            <a href=\"https://1drv.ms/b/s!AtCdnSj9ls2qhN4GxGkBtGwaJulLAA?e=MbHCqe\">\r\n                <Card title=\"Physics CEM\" bordered={false} hoverable={true}>\r\n                <Space direction=\"vertical\">\r\n                <FilePdfOutlined style={{ fontSize: '30px'}}/>\r\n                <Text type='secondary'> Size: 5M</Text>\r\n                <Tag color=\"green\">Online</Tag>\r\n                </Space>\r\n                </Card>\r\n            </a>\r\n            </Col>\r\n            </Row>\r\n            <Row gutter={16}>\r\n            <Col span={8}>\r\n            <a>\r\n                <Card title=\"Chemistry\" bordered={false} hoverable={true}>\r\n                <Space direction=\"vertical\">\r\n                <FilePdfOutlined style={{ fontSize: '30px'}}/>\r\n                <Tag color=\"red\">Offline</Tag>\r\n                </Space>\r\n                </Card>\r\n            </a>\r\n            </Col>\r\n            <Col span={8}>\r\n            <a>\r\n                <Card title=\"Microeconomics\" bordered={false} hoverable={true}>\r\n                <Space direction=\"vertical\">\r\n                <FilePdfOutlined style={{ fontSize: '30px'}}/>\r\n                <Tag color=\"red\">Offline</Tag>\r\n                </Space>\r\n                </Card>\r\n            </a>\r\n            </Col>\r\n            <Col span={8}>\r\n            <a>\r\n                <Card title=\"Physics 1 & CM\" bordered={false} hoverable={true}>\r\n                <Space direction=\"vertical\">\r\n                <FilePdfOutlined style={{ fontSize: '30px'}}/>\r\n                <Tag color=\"red\">Offline</Tag>\r\n                </Space>\r\n                </Card>\r\n            </a>\r\n            </Col>\r\n            </Row>\r\n            <Row gutter={16}>\r\n            <Col span={8}>\r\n            <a href=\"https://onedrive.live.com/redir.aspx?cid=aacd96fd289d9dd0&resid=AACD96FD289D9DD0!77461&parId=AACD96FD289D9DD0!104&authkey=!AL8wrY9_pFimlc\">\r\n                <Card title=\"Grade 10\" bordered={false} hoverable={true}>\r\n                <Space direction=\"vertical\">\r\n                <BookOutlined style={{ fontSize: '30px'}}/>\r\n                <Text type='secondary'>OneNote Online</Text>\r\n                <Tag color=\"green\">Online</Tag>\r\n                </Space>\r\n                </Card>\r\n            </a>\r\n            </Col>\r\n            <Col span={8}>\r\n            <a href=\"https://onedrive.live.com/redir.aspx?cid=aacd96fd289d9dd0&resid=AACD96FD289D9DD0!77399&parId=AACD96FD289D9DD0!104&authkey=!AEkcRuZGkkj5Pe0\">\r\n                <Card title=\"Grade 11\" bordered={false} hoverable={true}>\r\n                <Space direction=\"vertical\">\r\n                <BookOutlined style={{ fontSize: '30px'}}/>\r\n                <Text type='secondary'>OneNote Online</Text>\r\n                <Tag color=\"green\">Online</Tag>\r\n                </Space>\r\n                </Card>\r\n            </a>\r\n            </Col>\r\n            </Row>\r\n            </Space>\r\n            </div>\r\n\r\n          </div>\r\n        </Content>\r\n        <AppFooter/>\r\n      </Layout>\r\n    );\r\n};\r\n\r\nexport default MainNotes;","import React from 'react';\r\nimport '../App.css';\r\nimport 'moment/locale/zh-cn';\r\nimport 'antd/dist/antd.css';\r\nimport '../index.css';\r\nimport {PageHeader} from 'antd'\r\n\r\nfunction AppPageHeader(props){\r\n    return (\r\n        <PageHeader\r\n            className=\"site-page-header\"\r\n            onBack={() => window.history.back()}\r\n            title={props.title}\r\n            subTitle={props.subTitle}\r\n        />\r\n    );\r\n}\r\n\r\nexport default AppPageHeader;","import React from 'react';\r\nimport '../../App.css';\r\nimport 'moment/locale/zh-cn';\r\nimport 'antd/dist/antd.css';\r\nimport '../../index.css';\r\nimport { Image, Layout, Typography, Space, Tag, Divider } from 'antd';\r\n\r\n\r\nimport { InlineMath, BlockMath } from 'react-katex'\r\nimport 'katex/dist/katex.min.css';\r\nimport SyntaxHighlighter from 'react-syntax-highlighter';\r\nimport { lightfair } from 'react-syntax-highlighter/dist/esm/styles/hljs';\r\n\r\nimport AppHeader from '../../PublicComponent/Header';\r\nimport AppFooter from '../../PublicComponent/Footer';\r\nimport FailImage from '../../PublicComponent/FailImage';\r\nimport AppPageHeader from '../../PublicComponent/PageHeader';\r\n\r\nconst { Title, Text, Paragraph } = Typography;\r\nconst { Content } = Layout\r\nconst PhotoLink = process.env.PUBLIC_URL + '/Assets/'\r\n\r\nfunction HowDoNeuralNetworkWork(props){\r\n    window.scrollTo(0,0);\r\n    return(\r\n<Layout>\r\n        <AppHeader select=\"2\"/>\r\n        <Content className=\"site-layout\" style={{ padding: '0 24px', marginTop: 64 }}>\r\n        <AppPageHeader title=\"How Do Neural Network Work\"/>\r\n          <div className=\"site-layout-background\" style={{ padding: 16 }}>\r\n              <PostContent/>\r\n          </div>\r\n        </Content>\r\n        <AppFooter/>\r\n      </Layout>\r\n    );\r\n}\r\n\r\nexport default HowDoNeuralNetworkWork;\r\n\r\nfunction PostContent(){\r\n    return (\r\n        <Layout style={{ backgroundColor: \"white\", padding: \"0\"}}>\r\n        <div>\r\n        <Tag color=\"blue\">Neural Network</Tag> <Tag color=\"blue\">Artificial Intelligence</Tag><Tag color=\"blue\">Machine Learning</Tag>\r\n        </div>\r\n        <Divider></Divider>\r\n        <Paragraph>神经网络作为一种新兴的计算机技术被许多人称为一种全新的“编程范式”，与往常的算法编写不同，神经网络是一种“数据驱动”的编程方法。在往常的算法编写中，人们需要手动编写算法的逻辑，而在神经网络中，人们只需要为网络提供海量数据和参考答案，网络就会自动生成算法。那么神经网络到底是怎么工作的呢？</Paragraph>\r\n\r\n        <Paragraph>这篇文章会对机器学习中的神经网络为什么可以被训练&输出正确预测做出<Text strong>不严谨但直观</Text>的解释。</Paragraph>\r\n\r\n        <Title level={3}>0. 模型是一个函数</Title>\r\n        <Paragraph>我们可以将一个深度学习中的模型看做一个映射关系：</Paragraph>\r\n        <BlockMath math=\"\\text{Perception} \\rightarrow \\text{Output}\"/>\r\n        <Paragraph>对于一个深度学习模型是“感知”（模型可以获得的所有信息的总和）与一个“数字”或者 “决策\"之间的映射关系。所以我们可以将模型看作一个函数<InlineMath math=\"F(x)\"/>.</Paragraph>\r\n        <Paragraph>那么模型就可以被表示为：<InlineMath math=\"F(\\text{Perception}) =\\text{Output}\"/></Paragraph>\r\n        <Paragraph type=\"secondary\">Example: Alpha Go 可以被表示为 <InlineMath math=\"F(\\text{Chess State}) = \\text{Best Position for Next Chess}\"/> 这样一个函数</Paragraph>\r\n        <Paragraph>现在我们假设有这样的一个函数：对于<Text strong>任何定义域内的输入都一定会给出此时的最优输出</Text>。这样的一个理想函数我们记作<InlineMath math=\"G(x)\"/>(Ground Truth)。 当我们“训练”模型<InlineMath math=\"F(x)\"/>的时候，我们的目标就是让模型尽可能拟合<InlineMath math=\"G(x)\"/>。也就是说，我们想要通过训练使得我们的模型<InlineMath math=\"F(x)\"/> 的输出与事实（最优函数）<InlineMath math=\"G(x)\"/>的差距最小化。</Paragraph>\r\n\r\n        <Title level={3}>1. 什么是神经网络</Title>\r\n        <Paragraph>要知道为什么”神经网络“可以被用来拟合函数呢？首先我们先了解一下什么是“神经网络”。</Paragraph>\r\n        <Paragraph>神经网络由许多神经元相互连接而组成，每个神经元都有自己的参数<InlineMath math=\"\\theta\"/> 。我们可以将神经元描绘为一个函数 <InlineMath math=\" f(\\theta_i, x) = y\"/>。那么对于下面一个模型（<InlineMath math=\"F(\\Theta, x), \\quad \\Theta=\\lbrace \\theta_1, \\theta_2, \\dots, \\theta_n\\rbrace\"/>），我们可以写出它的数学表达式：</Paragraph>\r\n        <center><Image\r\n            width=\"350px\"\r\n            src={`${PhotoLink}HowDoNeuralNetworkWork4.png`}\r\n            fallback={FailImage}\r\n        /></center>\r\n        <BlockMath math=\"F(\\Theta, x) = f(\\theta_5, (f(\\theta_3, f(\\theta_2, x_2) + f(\\theta_1, x_1)), f(\\theta_4, f(\\theta_2, x_2))))\"/>\r\n\r\n        <Title level={3}>2. 神经网络可以拟合函数</Title>\r\n        <Paragraph>神经网络的本质建立在这样一个事实上：简单非线性函数的重复的迭代与叠加可以在拥有适当参数的情况下<Text strong>有限精度的拟合任何连续函数</Text>。下面的例子会给出一个<Text type=\"warning\">直观但不严谨的</Text>，对神经网络拟合二元函数的证明：</Paragraph>\r\n        <Paragraph>首先，我们可以用5个使用sigmoid函数的神经元来构建一个“高台”函数。(代码是具体的实现)</Paragraph>\r\n        <center><Space>\r\n        <Image\r\n            width=\"200px\"\r\n            src={`${PhotoLink}HowDoNeuralNetworkWork1.png`}\r\n            fallback={FailImage}\r\n        />\r\n        <Image \r\n            width=\"200px\"\r\n            src={`${PhotoLink}HowDoNeuralNetworkWork3.png`}\r\n            fallback={FailImage}\r\n        />\r\n        </Space></center>\r\n        <SyntaxHighlighter language=\"python\" style={lightfair}\r\n        children={\r\n            `\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport pylab\r\nfrom matplotlib import cm\r\nfrom mpl_toolkits.mplot3d import Axes3D\r\n\r\ndef sigmoid(x):\r\n    s = 1 / (1 + np.exp(-x))\r\n    return s\r\n\r\ndef tower(x, y, x_min, x_max, y_min, y_max):\r\n    x1 = sigmoid(1000 * (x - x_min))\r\n    x2 = sigmoid(1000 * (x - x_max))\r\n\r\n    y1 = sigmoid(1000 * (y - y_min))\r\n    y2 = sigmoid(1000 * (y - y_max))\r\n\r\n    z = x1-x2+y1-y2\r\n    z = sigmoid(30*(z-1.1))\r\n    return z\r\n\r\n\r\nX = np.arange(-5, 5, 0.1)\r\nY = np.arange(-5, 5, 0.1)\r\nX, Y = np.meshgrid(X, Y)\r\nZ = tower(X, Y, -0.3, 0.7, -0.2, 0.8)\r\nfig = plt.figure()\r\nax = Axes3D(fig)\r\nax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.viridis)\r\nplt.show()\r\n            `\r\n        }\r\n        />\r\n        <Paragraph>如果我们把这样的一个高台记作<InlineMath math=\"Tower(x_1, x_2,\\Theta)\"/>，那么通过组合足够多这些高台，我们可以得到任何一个连续二元函数的任意小精度拟合（缩小每个高台的面积），例如下图（左：原函数，右：四个<InlineMath math=\"Tower(x_1, x_2,\\Theta)\"/>的组合</Paragraph>\r\n        <center><Image\r\n            width=\"350px\"\r\n            src={`${PhotoLink}HowDoNeuralNetworkWork2.png`}\r\n            fallback={FailImage}\r\n        /></center>\r\n        <SyntaxHighlighter\r\n        style={lightfair}\r\n        language=\"python\"\r\n        children={\r\n        `\r\ndef tower(x, y, x_min, x_max, y_min, y_max):\r\n    x1 = sigmoid(1000 * (x - x_min))\r\n    x2 = sigmoid(1000 * (x - x_max))\r\n\r\n    y1 = sigmoid(1000 * (y - y_min))\r\n    y2 = sigmoid(1000 * (y - y_max))\r\n\r\n    z = x1-x2+y1-y2\r\n    z = sigmoid(4*(z-1.1))\r\n    return z\r\n\r\nZ = tower(X, Y, -0.5, 0.5, -0.5, 0.5) + tower(X, Y, -1, 1, -1, 1) + tower(X, Y, -2, 2, -2, 2) + tower(X, Y, -4, 4, -4, 4)\r\nfig = plt.figure()\r\nax = Axes3D(fig)\r\nax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.viridis)\r\nplt.show()\r\n        `\r\n        }\r\n        />\r\n\r\n        <Title level={3}>3. 如何让电脑自动调参？</Title>\r\n        <Paragraph>在上面的例子中，所有的参数都是人工设定的，因为只有20个不到的参数，人工设定是一种可行的做。可是目前绝大多数的模型都有超过一万个参数，参数最多的自然语言模型GPT-3甚至有1730亿个参数（存储整个模型需要800T空间）！在这么多参数的情况下，人工调节每一个参数变成了一项不可能的任务，所以我们需要让电脑来自动调整参数来让模型<InlineMath math=\"F(x)\"/>拟合到目标<InlineMath math=\"G(x)\"/>上。</Paragraph>\r\n        <Paragraph>要让电脑自动完成这项工作，我们需要先回想一下当我们调整参数时我们所作的工作：1. 评估现在的模型<InlineMath math=\"F(x)\"/>与<InlineMath math=\"G(x)\"/>相差大不大（现在的模型是不是一个好模型）2. 预测调节参数<InlineMath math=\"\\theta\"/>（调大/调小）以后模型会变好还是变坏 3. 如果参数<InlineMath math=\"\\theta\"/>调小可以让模型<InlineMath math=\"F(x)\"/>更加接近<InlineMath math=\"G(x)\"/>，那么就调小<InlineMath math=\"\\theta\"/>， 反之亦然</Paragraph>\r\n        <Title level={4}>损失函数</Title>\r\n        <Paragraph>为了让机器拥有完成任务1的能力，人们设计出了“损失函数”用来量化表示模型<InlineMath math=\"F(x)\"/>与事实<InlineMath math=\"G(x)\"/>之间的差距，用<InlineMath math=\"L(\\hat{y}, y)\"/>表示，<InlineMath math=\"\\hat{y}\"/>表示模型的输出（对Ground Truth <InlineMath math=\"y\"/>的预测值），一般来说，一个良好的损失函数应该有这些性质：</Paragraph>\r\n\r\n        <Paragraph>1. 损失函数大小与模型质量单调递增 - 模型越差，损失函数越大\r\n        2. 损失函数应该是一个连续，尽量平滑的函数</Paragraph>\r\n\r\n        <Paragraph>一种常见的损失函数是<InlineMath math=\"L(\\hat{y}, y) = (y - \\hat{y})^2\"/></Paragraph>\r\n\r\n        <Title level={4}>参数调节方向的计算</Title>\r\n        <Paragraph>为了让机器完成任务2 和 3，我们需要将”预测调节参数<InlineMath math=\"\\theta\" />（调大/调小）以后模型会变好还是变坏“这样一个主观的过程用数学方法表达出来。因为我们已经引入了损失函数，所以实际上这个过程可以被表述为“预测如何调节参数<InlineMath math=\"\\theta\"/>（调大/调小）可以减小损失函数的值”</Paragraph>\r\n\r\n        <Paragraph>在此之前，我们先看一看我们如何最小化一个一元函数<InlineMath math=\"h(x)\"/>. 对于一个一元函数，我们可以计算出当前位置的一阶导数<InlineMath math=\"dh/dx\"/>。如果一阶导数是正数，说明增大<InlineMath math=\"x\"/>可以增大<InlineMath math=\"h(x)\"/>，反之亦然。所以要最小化<InlineMath math=\"h(x)\"/>，我们只需要不停的执行下面这一个操作：</Paragraph>\r\n        <BlockMath math=\"x\\stackrel{\\text{update}}{\\longrightarrow}x - \\eta \\cdot \\frac{dh(x)}{dx},\\quad\\quad \\text{where $\\eta$ is a positive number}\"/>\r\n        <Paragraph>这里的<InlineMath math=\"\\eta\"/>是一个参数“学习速率”，学习速率越高，每次更新<InlineMath math=\"x\"/>的时候<InlineMath math=\"x\"/>的值就会改变越多 。</Paragraph>\r\n        <Paragraph>有了上面的铺垫，解决“预测如何调节参数<InlineMath math=\"\\theta\"/>（调大/调小）可以减小损失函数的值”的方法就很明显了：计算<InlineMath math=\"\\partial L(\\hat{y}, y)/\\partial \\theta\"/> 并且将<InlineMath math=\"\\theta\"/>按照一下方式更新：</Paragraph>\r\n        <BlockMath math=\"\\theta\\stackrel{\\text{update}}{\\longrightarrow}\\theta - \\eta \\cdot \\frac{\\partial L(\\hat{y}, y)}{\\partial\\theta},\\quad\\quad \\text{where $\\eta$ is a positive number}\"/>\r\n        <Paragraph type=\"secondary\"> 有些人可能会疑惑，在<InlineMath math=\"L(\\hat{y}, y)\"/>中明明都没有自变量 <InlineMath math=\"\\theta\"/> 啊，怎么计算<InlineMath math=\"\\frac{\\partial L(\\hat{y}, y)}{\\partial \\theta}\"/> 呢？</Paragraph>\r\n\r\n        <Paragraph type=\"secondary\">实际上注意到损失函数的第一个输入时<InlineMath math=\"\\hat{y}\"/>，也就是模型的输出，而模型可以表示为<InlineMath math=\"F(\\theta, x)\"/>，所以我们可以通过<Text strong>链式法则</Text>计算<InlineMath math=\"\\frac{\\partial L(\\hat{y}, y)}{\\partial\\theta}\"/>\r\n        <BlockMath math=\"\\frac{\\partial L(\\hat{y}, y)}{\\partial \\theta} = \\frac{\\partial L(\\hat{y}, y)}{\\partial \\hat{y}}\\cdot \\frac{\\partial \\hat{y}}{\\partial \\theta}\"/>\r\n        这也是神经网络的基石 - 反向传播算法 (Back Propagation) 的数学原理\r\n        </Paragraph>\r\n        <Paragraph>当机器拥有了自动更新权重的能力的时候，我们就可以开始对神经网络进行训练了！训练的过程其实就是将样本从训练数据集中输入到模型中，再通过算法自动调节模型函数来最小化损失函数。</Paragraph>\r\n        </Layout>\r\n    );\r\n}\r\n","import React from 'react';\r\nimport '../../App.css';\r\nimport 'moment/locale/zh-cn';\r\nimport 'antd/dist/antd.css';\r\nimport '../../index.css';\r\nimport { Image, Layout, Typography, Tag, Divider } from 'antd';\r\n\r\nimport { InlineMath, BlockMath } from 'react-katex'\r\nimport 'katex/dist/katex.min.css';\r\nimport SyntaxHighlighter from 'react-syntax-highlighter';\r\nimport { lightfair } from 'react-syntax-highlighter/dist/esm/styles/hljs';\r\n\r\nimport AppHeader from '../../PublicComponent/Header';\r\nimport AppFooter from '../../PublicComponent/Footer';\r\nimport FailImage from '../../PublicComponent/FailImage';\r\nimport AppPageHeader from '../../PublicComponent/PageHeader';\r\n\r\nconst { Title, Text, Paragraph, Link } = Typography;\r\nconst { Content } = Layout\r\nconst PhotoLink = process.env.PUBLIC_URL + '/Assets/'\r\n\r\nfunction WhatIsLSTM(){\r\n    window.scrollTo(0,0);\r\n    return(\r\n        <Layout>\r\n        <AppHeader select=\"2\"/>\r\n        <Content className=\"site-layout\" style={{ padding: '0 24px', marginTop: 64 }}>\r\n        <AppPageHeader title=\"What is LSTM\"/>\r\n          <div className=\"site-layout-background\" style={{ padding: 16 }}>\r\n              <PostContent/>\r\n          </div>\r\n        </Content>\r\n        <AppFooter/>\r\n      </Layout>\r\n    );\r\n}\r\n\r\nexport default WhatIsLSTM;\r\n\r\nfunction PostContent(){\r\n    return(\r\n    <Layout style={{ backgroundColor: \"white\", padding: \"0\"}}>\r\n        <div>\r\n        <Tag color=\"blue\">Neural Network</Tag> <Tag color=\"blue\">Artificial Intelligence</Tag> <Tag color=\"blue\">Marhine Learning</Tag>\r\n        <Divider></Divider>\r\n        </div>\r\n        <Paragraph>一般的神经网络只能处理单个信息，可是有的时候神经网络的输入是一个时间序列，在这种情况下普通的前馈神经网络就不能利用“上下文”中隐含的信息来更好的处理当前输入。为了解决这个问题，人们提出了递归神经网络(Recurrent Neural Network, RNN)。可是递归神经网络也有问题：由于同样的权重在网络中一直被累乘，在反向传播的时候极容易出现梯度消失与梯度爆炸的问题。同时，由于RNN在状态间传递的信息过少，RNN在上下文距离较远的时候会很快的遗忘前文信息。为了解决这些问题，人们提出了LSTM这个新的网络模型，它可以很好的处理以上这些问题。</Paragraph>\r\n        <Title level={2}>LSTM - 过去，现在，和未来</Title>\r\n        <Paragraph><Text strong>0. 什么是LSTM</Text></Paragraph>\r\n        <Paragraph><Text strong>1. 为什么需要LSTM</Text></Paragraph>\r\n        <Paragraph><Text strong>2. LSTM的直觉解释</Text></Paragraph>\r\n        <Paragraph><Text strong>3. LSTM的具体解释</Text></Paragraph>\r\n        <Paragraph><Text strong>4. LSTM的变体</Text></Paragraph>\r\n        <Paragraph><Text strong>5. 参考资料</Text></Paragraph>\r\n        <hr />\r\n        <Title level={3}>0. 什么是LSTM</Title>\r\n        <Paragraph>LSTM，全称 Long Short Term Memory (长短期记忆) 是一种特殊的<Text strong>递归神经网络</Text> 。这种网络 \r\n        与一般的前馈神经网络不同，LSTM可以利用时间序列对输入进行分析；简而言之，当使用前馈神经网络时，神经网络会认为我们<InlineMath math=\"t\"/>时刻输入的内容与<InlineMath math=\"t + 1\"/>时刻输入的内容<Text strong>完全无关</Text>，对于许多\r\n        情况，例如图片分类识别，这是毫无问题的，可是对于一些情景，例如<Text strong>自然语言处理</Text> (NLP, Natural Language Processing) 或者我们需要分析类似于<Text strong>连拍照片</Text>这样的数据时，合理运用 <InlineMath math=\"t\"/> 或\r\n        之前的输入来处理 <InlineMath math=\"t+n\"/> 时刻显然可以更加合理的运用输入的信息。为了运用到时间维度上信息，人们设计了<Text strong>递归神经网络</Text> (RNN, Recurssion Neural Network)，一个简单的递归神经网络可以用这种方式表示</Paragraph>\r\n        <center><Image alt=\"image-20200402223614052\" src={`${PhotoLink}LSTM1.png`} width=\"200px\" fallback={FailImage}/></center>\r\n        <Paragraph>在图中，<InlineMath math=\"x_t\"/>是在<InlineMath math=\"t\"/>时刻的输入信息，<InlineMath math=\"h_t\"/>是在<InlineMath math=\"t\"/>时刻的输入信息，我们可以看到神经元<InlineMath math=\"A\"/>会递归的调用自身并且将<InlineMath math=\"t -1\"/>时刻的信息传递给<InlineMath math=\"t\"/>时刻。</Paragraph>\r\n        <Paragraph>递归神经网络在许多情况下运行良好，特别是在对<Text strong>短时间序列</Text>数据的分析时十分方便。但是， \r\n        注意到前面着重强调了“短”，这是为什么呢？</Paragraph>\r\n        <Paragraph>上图所示的简单递归神经网络存在一个“硬伤“，<Text strong>长期依赖问题</Text>：递归神经网络只能处理我们需 \r\n        要较接近的上下文的情况：</Paragraph>\r\n        <Paragraph type=\"secondary\">\r\n        <Paragraph>Example 1. 想象现在设计了一个基于简单RNN的句子自动补全器，当我输入\"Sea is ...\" 的时候会自动补全为\"Sea is <Text strong>blue</Text>\"。</Paragraph>\r\n        </Paragraph>\r\n        <Paragraph>在这种情况下，我们需要的上下文极短，而RNN可以很好的收集到 <InlineMath math=\"t = 0\"/>时的信息\"Sea\"并且补\r\n        上\"blue\"</Paragraph>\r\n        <Paragraph type=\"secondary\">\r\n        <Paragraph>Example 2. 现在，假设我们用刚刚的RNN试图补全一篇文章\"我一直呆在中国，……，我会说一口流利的 (?)\"。</Paragraph>\r\n        </Paragraph>\r\n        <Paragraph>在这里，为了补全最后的空缺，需要的信息在非常远的上文（e.g. 200+字前）提到的”中国“。在实验中简单的理想状\r\n        态下，经过精心调节的RNN超参数可以良好的将这些信息向后传递。可是在现实的情况中，基本没有RNN可以做到这一点。一些学者\r\n        后来研究发现RNN的长期依赖问题是这种网络结构本身的问题。</Paragraph>\r\n        <Paragraph>不但如此，这种简单的RNN还很容易受到两种在神经网络中臭名昭著的影响<Text strong>梯度消失问题</Text>（神经\r\n        网络的权重/偏置梯度极小，导致神经网络参数调整速率急剧下降）和<Text strong>梯度爆炸问题</Text>（神经网络的权重/偏置\r\n        极大，导致神经网络参数调整幅度过大，矫枉过正）。相信大家都看过一个著名的鸡汤，<InlineMath math=\"(0.99)^{365}\"/>和<InlineMath math=\"(1.01)^{365}\"/>的对比。实际上，这个鸡汤非常好的描述了梯度问题的本质：对于<Text strong>任意信息递 \r\n        归使用足够多次同样的计算</Text>，都会导致极大或极小的结果，也就是说…</Paragraph>\r\n        <Paragraph>根据微分链式法则，在RNN中，神经元的权重的梯度可以被表示为一系列函数的微分的连乘。因为神经元的参数（权重\r\n        与偏置）都是基于学习速率（一般为常数）和参数梯度相反数（使得神经网络输出最快逼近目标输出）得到的，一个过大或过小的\r\n        梯度会导致我们要么需要极长的训练时间（本来从-2.24 调节到 -1.99 只用500个样本，由于梯度过小，每次只调小0.0001，最后\r\n        用了几千个样本），要么会导致参数调节过度（例如本来应该从-10.02调节到-9.97，由于梯度过大，直接调成了+20.3）</Paragraph>\r\n        <Title level={3}>1. 为什么需要LSTM</Title>\r\n        <Paragraph>LSTM从被设计之初就被明确的用于解决一般递归神经网络中普遍存在的<Text strong>长期依赖问题</Text>，使用LSTM可以有效的传递和表达长时间序列中的信息并且不会导致长时间前的有用信息被忽略（遗忘）。与此同时，LSTM还可以解决RNN中\r\n        的梯度消失/爆炸问题</Paragraph>\r\n        <Title level={3}>2. LSTM 的直觉解释</Title>\r\n        <Paragraph>LSTM的设计或多或少的借鉴了人类对于自然语言处理的直觉性经验。要想了解LSTM的工作机制，可以先阅读一下一个 \r\n        （虚构的）淘宝评论：</Paragraph>\r\n        <Paragraph type=\"secondary\">\r\n        <Paragraph>“这个笔记本非常棒，纸很厚，料很足，用笔写起来手感非常舒服，而且没有一股刺鼻的油墨味；更加好的是这个笔记\r\n        本不但便宜还做工优良，我上次在别家买的笔记本裁纸都裁不好，还会割伤手……”</Paragraph>\r\n        </Paragraph>\r\n        <Paragraph>如果让你看完这段话以后马上转述，相信大多数人都会提取出来这段话中几个重要的关键词“纸好”，“没味道”，“做工\r\n        好”，然后再重新组织成句子进行转述。这说明了以下两点：</Paragraph>\r\n        <ol>\r\n        <li>在一个时间序列中，不是所有信息都是同等有效的，大多数情况存在“关键词”或者“关键帧”</li>\r\n        <li>我们会在从头到尾阅读的时候“自动”概括已阅部分的内容并且用之前的内容帮助理解后文</li>\r\n        </ol>\r\n        <Paragraph>基于以上这两点，LSTM的设计者提出了“长短期记忆”的概念——只有一部分的信息需要长期的记忆，而有的信息可以不 \r\n        记下来</Paragraph>\r\n        <Title level={3}>3. LSTM的具体解释</Title>\r\n        <Paragraph>一个普通的，使用tanh函数的RNN可以这么表示：</Paragraph>\r\n        <center><Image alt=\"image-20200402233238756\" src={`${PhotoLink}LSTM2.png`} width=\"50%\" fallback={FailImage}/></center>\r\n        <Paragraph>在这里，我们可以看到A在<InlineMath math=\"t-1\"/>时刻的输出值<InlineMath math=\"h_t\"/>被复制到了<InlineMath math=\"t\"/>时刻，与<InlineMath math=\"t\"/>时刻的输入<InlineMath math=\"x_t\"/>整合后经过一个带权重和偏置的tanh函数后\r\n        形成输出，并继续将数据复制到<InlineMath math=\"t+1\"/>时刻……</Paragraph>\r\n        <Paragraph>与上图朴素的RNN相比，单个LSTM单元拥有更加复杂的内部结构和输入输出：</Paragraph>\r\n        <center><Image alt=\"image-20200402233826864\" src={`${PhotoLink}LSTM3.png`} width=\"50%\" fallback={FailImage}/></center>\r\n        <Paragraph>在上图中，每一个红色圆形代表对向量做出的操作（pointwise operation， 对位操作），而黄色的矩形代表一个神 \r\n        经网络层，上面的字符代表神经网络所使用的激活函数</Paragraph>\r\n        <Paragraph type=\"secondary\">\r\n        <Paragraph>point-wise operation 点对点操作</Paragraph>\r\n        <Paragraph>​ 如果我要对向量&lt;1, 2, 3&gt; 和 &lt;1, 3, 5&gt;进行逐分量的想成操作，会获得结果 &lt;1, 6, 15&gt;</Paragraph>\r\n        <Paragraph>layer 函数层</Paragraph>\r\n        <Paragraph>​ 一个函数层拥有两个属性：权重向量(Weight) 和 偏置向量(bias)，对于输入向量<InlineMath math=\"A\"/>的每一 \r\n        个分量 <InlineMath math=\"i\"/> ， 函数  层会对其进行以下操作(假设激活函数为<InlineMath math=\"F(x)\"/>)：\r\n        <BlockMath math=\"\r\n        Output_i = F(W_i \\cdot A_i + b_i)\r\n        \"/>\r\n        ​ 常见的激活函数（也就是套在最外面的<InlineMath math=\"F(x)\"/>）有ReLU(线性修正单元)，sigmoid（写作<InlineMath math=\"\\sigma\"/>），和 <InlineMath math=\"    anh\"/></Paragraph>\r\n        </Paragraph>\r\n        <Title level={4}>LSTM的关键：单元状态</Title>\r\n        <Paragraph>LSTM能够从RNN中脱颖而出的关键就在于上图中从单元中贯穿而过的线 ——神经元的隐藏态，我们可以将神经元的隐藏 \r\n        态简单的理解成递归神经网络对于输入数据的“记忆”，用<InlineMath math=\"C_t\"/>表示神经元在<InlineMath math=\"t\"/>时刻过\r\n        后的“记忆”，这个向量涵盖了在<InlineMath math=\"t+1\"/>时刻前神经网络对于所有输入信息的“概括总结”</Paragraph>        \r\n        <center><Image alt=\"image-20200402235227710\" src={`${PhotoLink}LSTM4.png`} width=\"50%\" fallback={FailImage}/></center>\r\n        <Paragraph>接下来我们会看一下LSTM四个函数层分别在做些什么</Paragraph>\r\n        <Title level={4}>LSTM_1 遗忘门</Title>\r\n        <center><Image alt=\"image-20200403003547037\" src={`${PhotoLink}LSTM5.png`} width=\"50%\" fallback={FailImage}/></center>\r\n        <Paragraph>对于上一时刻LSTM中的单元状态来说，一些“信息”可能会随着时间的流逝而“过时”。为了不让过多记忆影响神经网络 \r\n        对现在输入的处理，我们应该选择性遗忘一些在之前单元状态中的分量——这个工作就交给了“遗忘门”</Paragraph>\r\n        <Paragraph>每一次输入一个新的输入，LSTM会先根据新的输入和上一时刻的输出决定遗忘掉之前的哪些记忆——输入和上一步的输 \r\n        出会整合为一个单独的向量，然后通过sigmoid神经层，最后点对点的乘在单元状态上。因为sigmoid 函数会将任意输入压缩到<InlineMath math=\"(0, 1)\"/>的区间上，我们可以非常直觉的得出这个门的工作原理 —— 如果整合后的向量某个分量在通过sigmoid \r\n        层后变为0，那么显然单元状态对应的分量也会变成0，换句话说，“遗忘”了这个分量上的信息；如果某个分量通过sigmoid层后为1，单元状态会“保持完整记忆”。不同的sigmoid输出会带来不同信息的记忆与遗忘。通过这种方式，LSTM可以<Text strong>长期记\r\n        忆重要信息</Text>，并且记忆可以随着时间进行动态调整</Paragraph>\r\n        <Paragraph>下面的公式可以用来描述遗忘门的计算，其中<InlineMath math=\"f_t\"/>就是sigmoid神经层的输出向量：\r\n        <BlockMath math=\"\r\n        f_t = \\sigma(W_f\\cdot [h_{t-1}, x_t] + b_f)\r\n        \"/></Paragraph>\r\n        <Title level={4}>LSTM_2 &amp; 3 记忆门</Title>\r\n        <Paragraph>记忆门是用来控制是否将在<InlineMath math=\"t\"/>时刻（现在）的数据并入单元状态中的控制单位。首先，用tanh \r\n        函数层将现在的向量中的有效信息提取出来，然后使用（图上tanh函数层左侧）的sigmoid函数来控制这些记忆要放“多少”进入单 \r\n        元状态。这两者结合起来就可以做到：</Paragraph>\r\n        <center><Image alt=\"image-20200403001917424\" src={`${PhotoLink}LSTM6.png`} width=\"50%\" fallback={FailImage}/></center>\r\n        <ol>\r\n        <li>从当前输入中提取有效信息</li>\r\n        <li>对提取的有效信息做出筛选，为每个分量做出评级(0 ~ 1)，评级越高的最后会有越多的记忆进入单元状态</li>\r\n        </ol>\r\n        <Paragraph>下面的公式可以分别表示这两个步骤在LSTM中的计算：</Paragraph>\r\n        <ol>\r\n        <li>\r\n        <Paragraph><BlockMath math=\"\r\n        C'_t = \\tanh(W_c\\cdot [h_{t - 1},x_t] + b_c)\r\n        \"/></Paragraph>\r\n        </li>\r\n        <li>\r\n        <Paragraph><BlockMath math=\"\r\n        i_t = \\sigma(W_i\\cdot [h_{t-1}, x_t] + b_i)\r\n        \"/></Paragraph>\r\n        </li>\r\n        </ol>\r\n        <Title level={4}>LSTM_4 输出门</Title>\r\n        <Paragraph>输出门，顾名思义，就是LSTM单元用于计算当前时刻的输出值的神经层。输出层会先将当前输入值与上一时刻输出值 \r\n        整合后的向量（也就是公式中的<InlineMath math=\"[h_{t - 1},x_t]\"/>）用sigmoid函数提取其中的信息，接着，会将当前的单 \r\n        元状态通过tanh函数压缩映射到区间<InlineMath math=\"(-1, 1)\"/>中*</Paragraph>\r\n        <Paragraph type=\"secondary\">\r\n        <Paragraph><Text strong>为什么我们要在LSTM的输出门上使用tanh函数？</Text></Paragraph>\r\n        <Paragraph>以下引用自Stack Overflow上问题 What is the intuition of using tanh in LSTM 中的最佳答案：</Paragraph>  \r\n        <Link href=\"https://stackoverflow.com/questions/40761185/what-is-the-intuition-of-using-tanh-in-lstm\" >https://stackoverflow.com/questions/40761185/what-is-the-intuition-of-using-tanh-in-lstm</Link>   \r\n        <Paragraph>在LSTM的输入和输出门中使用tanh函数有以下几个原因：</Paragraph>\r\n        <ol>\r\n        <li>为了防止<Text strong>梯度消失问题</Text>，我们需要一个二次导数在大范围内不为0的函数，而tanh函数可以满足\r\n        这一点</li>\r\n        <li>为了便于凸优化，我们需要一个<Text strong>单调函数</Text></li>\r\n        <li>tanh函数一般收敛的更快</li>\r\n        <li>tanh函数的求导占用系统的资源更少</li>\r\n        </ol>\r\n        </Paragraph>\r\n        <Paragraph>将经过tanh函数处理后的单元状态与sigmoid函数处理后的，整合后的向量点对点的乘起来就可以得到LSTM在<InlineMath math=\"t\"/>时刻的输出了！</Paragraph>\r\n        <hr />\r\n        <Title level={3}>4. LSTM 的变体</Title>\r\n        <Paragraph>自从LSTM在自然语言处理等方面大获成功后，许多种LSTM的变体被提出，其中只有几种值得特别关注：</Paragraph> \r\n        <center><Image alt=\"image-20200403021009010\" src={`${PhotoLink}LSTM7.png`} width=\"50%\" fallback={FailImage}/></center>\r\n        <Paragraph>这种LSTM让各个门都可以在获得了上一时刻的单元状态的前提下进行运算。在上面的图中，单元状态被额外赋予到了 \r\n        所有三个层中（输出门除外），然而在实际的应用中，大部分研究者只会选择性的打开三个通道中的一或两个</Paragraph>      \r\n        <Paragraph>除此之外，还有很多其他LSTM变体以及<Text strong>通过其他方式构建RNN达到类似LSTM的效果的架构</Text>，然而\r\n        这些架构的效率都大同小异，所以不过多说明了</Paragraph>\r\n        <Title level={3}>5. 参考资料</Title>\r\n        <Paragraph>[1] “Understanding LSTM Networks.” <em>Understanding LSTM Networks -- Colah's Blog</em>, colah.github.io/posts/2015-08-Understanding-LSTMs/.</Paragraph>\r\n        <Paragraph>[2] “Long Short-Term Memory.” <em>Wikipedia</em>, Wikimedia Foundation, 1 Apr. 2020, en.wikipedia.org/wiki/Long_short-term_memory.</Paragraph>\r\n        <Paragraph>[3] “LSTM以及三重门，遗忘门，输入门，输出门.” <em>LSTM以及三重门，遗忘门，输入门，输出门_网络_Lison_Zhu's Blog-CSDN博客</em>, blog.csdn.net/Lison_Zhu/article/details/97236501.</Paragraph>\r\n        <Paragraph>[4] “递归神经网络问题整理.” <em>递归神经网络问题整理_网络_leo鱼的博客-CSDN博客</em>, blog.csdn.net/webzjuyujun/article/details/71124695.</Paragraph>\r\n        <Paragraph>[5] “详解机器学习中的梯度消失、爆炸原因及其解决方法.” <em>详解机器学习中的梯度消失、爆炸原因及其解决方 \r\n        法_网络_Double_V的博客-CSDN博客</em>, blog.csdn.net/qq_25737169/article/details/78847691.</Paragraph>\r\n        <Paragraph>[6] Dnkdnk. “What Is the Intuition of Using Tanh in LSTM.” <em>Stack Overflow</em>, 1 Sept. 1966, stackoverflow.com/questions/40761185/what-is-the-intuition-of-using-tanh-in-lstm.</Paragraph>\r\n        </Layout>);\r\n}","import React from 'react';\r\nimport {HashRouter, Route, Switch} from 'react-router-dom';\r\n\r\nimport MainContent from './Main/MainPage';\r\nimport MainPost from './Posts/PostsMain';\r\nimport MainNotes from './Notes/NotesMain';\r\n\r\nimport HowDoNeuralNetworkWork from './Posts/MyPosts/HowDoNeuralNetworkWork';\r\nimport WhatIsLSTM from './Posts/MyPosts/WhatIsLSTM';\r\n\r\nconst BasicRoute = () => (\r\n    <HashRouter>\r\n        <Switch>\r\n            <Route exact path=\"/\" component={MainContent}/>\r\n            <Route exact path=\"/posts\" component={MainPost}/>\r\n            <Route exact path=\"/notes\" component={MainNotes}/>\r\n\r\n            <Route exact path=\"/posts/HowDoNeuralNetworkWork\" component={HowDoNeuralNetworkWork}/>\r\n            <Route exact path=\"/posts/WhatIsLSTM\" component={WhatIsLSTM}/>\r\n        </Switch>\r\n    </HashRouter>\r\n);\r\n\r\n\r\nexport default BasicRoute;","import './App.css';\nimport BasicRoute from './Router';\n\nfunction App() {\n  return (\n    <BasicRoute/>\n  );\n}\n\nexport default App;\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}